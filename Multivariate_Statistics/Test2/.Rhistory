hist(bsStat)
length(bsStat[bsStat>0])/length(bsStat)
t.test(femalesKeep,males,alternative="two.sided",var.equal = F)
t.test(femalesKeep,males,alternative="one.sided",var.equal = F)
t.test(femalesKeep,males,alternative="less",var.equal = F)
length(bsStat[bsStat>0])/length(bsStat)
t.test(femalesKeep,males,alternative="greater",var.equal = F)
t.test(femalesKeep,males,alternative="less",var.equal = F)
help("t.test")
p.val.bs = length(bsStat[bsStat>0])/length(bsStat)
p.val.bs
hist(bsStat)
hist(femalsKeep)
hist(femalesKeep)
hist(males)
hist(femalesKeep-males)
hist(bsStat)
hist(femalesKeep-males)
hist(bsStat)
mean(femalesKeep)-mean(males)
mean(femalesKeep)-mean(males)
asdf=maleBS-femBS
length(asdf[bsStat<0])/asdf(bsStat)
length(asdf[bsStat<0])/length(asdf)
length(asdf[bsStat>0])/length(asdf)
library(matlib)
library(tidyr)
#read File
salarys= read.csv(file = 'C:/Users/User/Desktop/School/Math 536/HW/HW1/HW1P1.csv')
#seperate classes
males=salarys['Males']
females=salarys['Females']
males=as.matrix(males)
#Drop rows with no data in Females
femalesKeep=females[complete.cases(females), ]
#Theoretical t.test for values
t.test(femalesKeep,males,alternative="less",var.equal = F)
femBS = rep(0,1000000)
maleBS = rep(0,1000000)
bsStat = rep(0,1000000)
#bootstraping
for(i in 1:1000000){
femBS[i]=mean(sample(femalesKeep,104,replace=T))
maleBS[i]=mean(sample(males,115,replace=T))
bsStat[i]=femBS[i]-maleBS[i]
}
#find lower and uperbounds for CI
lb.fbs = sort(bsStat)[1000000*.05]
ub.fbs = sort(bsStat)[1000000*.95]
lb.fbs
ub.fbs
#Generate P-values
p.val.bs = length(bsStat[bsStat>0])/length(bsStat)
p.val.bs
#create histogram
hist(bsStat)
0.01427-0.012675
help("cut")
#create histogram
h=hist(bsStat)
cuts=cut(h$breaks,c(-Inf,0.9999,0,Inf))
plot(h,col=c("white","red"))
plot(h,col=c("white","red")[cuts])
plot(h,col=c("white","red")[cuts])
#create histogram
h=hist(bsStat, breaks=100,plot=F)
cuts=cut(h$breaks,c(-Inf,0.9999,0,Inf))
plot(h,col=c("white","red")[cuts])
cuts=cut(h$breaks,c(-Inf,-0.000001,0,Inf))
plot(h,col=c("white","red")[cuts])
#create histogram
h=hist(bsStat, breaks=100,plot=F)
cuts=cut(h$breaks,c(-Inf,-0.000001,0,Inf))
plot(h,col=c("white","red")[cuts])
#create histogram
h=hist(bsStat,plot=F)
cuts=cut(h$breaks,c(-Inf,-0.000001,0,Inf))
plot(h,col=c("white","red")[cuts])
cuts=cut(h$breaks,c(-Inf,-0.000001,0,100000))
plot(h,col=c("white","red")[cuts])
cuts=cut(h$breaks,c(-Inf,-0.000001,Inf))
plot(h,col=c("white","red")[cuts])
#create histogram
h=hist(bsStat,breaks=100,plot=F)
cuts=cut(h$breaks,c(-Inf,-0.000001,Inf))
plot(h,col=c("white","red")[cuts])
plot(h,main="Bias Toward Higher Men Salaries",col=c("white","red")[cuts])
p.val.bs
#bootstraping
for(i in 1:1000000){
#creating populations to use in bootstraping statistic
femBS[i]=mean(sample(femalesKeep,104,replace=T))
maleBS[i]=mean(sample(males,115,replace=T))
#creating bootstraping statistic
bsStat[i]=maleBS[i]-femBS[i]
}
#Generate P-values for boostraping using >0 as the cut off for difference
p.val.bs = length(bsStat[bsStat>0])/length(bsStat)
p.val.bs
for(i in 1:1000000){
#creating populations to use in bootstraping statistic
femBS[i]=mean(sample(femalesKeep,104,replace=T))
maleBS[i]=mean(sample(males,115,replace=T))
#creating bootstraping statistic
bsStat[i]=femBS[i]-maleBS[i]
#bootstraping
for(i in 1:1000000){
#creating populations to use in bootstraping statistic
femBS[i]=mean(sample(femalesKeep,104,replace=T))
maleBS[i]=mean(sample(males,115,replace=T))
#creating bootstraping statistic
bsStat[i]=femBS[i]-maleBS[i]
}
knitr::opts_chunk$set(echo = TRUE)
trivariatenormal <- read.table("C:/Users/Amanda/Desktop/Math 534/Homework 10/trivariatenormal.dat", quote="\"", comment.char="",header=T)
knitr::opts_chunk$set(echo = TRUE)
trivariatenormal <- read.table("trivariatenormal.dat", quote="\"", comment.char="",header=T)
View(trivariatenormal)
attach(trivariatenormal)
setwd("C:/Users/User/Desktop/School/Math_534/HW/HW5")
mu=c(0,0,0)
sig=matrix(c(1,0,0,0,1,0,0,0,1),3,3)
maxit=50
em=function(X,mu,sig,maxit){
#browser()
n=dim(X)[1]
p=dim(X)[2]
it=0
stop=0
header=paste0("  it","   mu1  ","    mu3  ","   Sig11","    Sig13  ","   ||grad||   ")
print(header,quote = FALSE)
while(it<maxit && stop==0){
it=it+1
ex1=matrix(0,p,1)
exx1=matrix(0,p,p)
for(i in 1:n){
ex=t(as.matrix(X[i,]))
exx=matrix(0,p,p)
obs=which(!is.na(X[i,]))
mis=which(is.na(X[i,]))
if(any(is.na(X[i,]))==TRUE ){
mu_o=matrix(mu[obs])
mu_m=matrix(mu[mis])
Soo = matrix(sig[obs,obs], length(obs), length(obs))
Smo = matrix(sig[mis,obs], length(mis), length(obs))
Som = matrix(sig[obs,mis], length(obs), length(mis))
Smm = matrix(sig[mis,mis], length(mis), length(mis))
yo=t(as.matrix(X[i,obs]))
y.m.star=mu_m+Smo%*%solve(Soo)%*%(yo-mu_o)
ex[mis]=y.m.star
exx[obs,obs] = yo%*%t(yo)
exx[mis,obs] = y.m.star%*%t(yo)
exx[obs,mis] = yo%*%t(y.m.star)
exx[mis,mis] = Smm-Smo%*%solve(Soo)%*%Som+y.m.star%*%t(y.m.star)
}
else{
yo=t(as.matrix(X[i,obs]))
exx[obs,obs]=yo%*%t(yo)
}
ex1=ex+ex1
exx1=exx+exx1
}
# e-step
#
x.bar.star=ex1/n
s.star=exx1/n
#m-step
#
mu.hat=x.bar.star
sig.hat=s.star-x.bar.star%*%t(x.bar.star)
# gradient
#
invsig=solve(sig)
gradM=-n*invsig%*%(mu-x.bar.star)
A = s.star-mu%*%t(x.bar.star)-x.bar.star%*%t(mu)+mu%*%t(mu)
B = invsig%*%(sig-A)%*%invsig
C=(-n/2)*(B+t(B)-diag(diag(B)))
gradS=C[upper.tri(C,diag = TRUE)==TRUE]
grad=matrix(0,p+p*(p+1)/2,1)
grad[1:p] = gradM
grad[(p+1):length(grad)] = gradS
norm=norm(grad,type = "f")
# reassigning mu and sig
#
if(it==1||it==2||it==3||it==33||it==34||it==35){
print(sprintf(' %2.0f %8.5f %8.5f %8.5f %8.5f %8.7f ',(it-1),mu[1],mu[3],sig[1,1],sig[1,3],norm),quote=FALSE)
}
mu=mu.hat
sig=sig.hat
if(norm<1e-6)stop=1
}
list(mu=mu,sig=sig)
}
em(trivariatenormal,mu,sig,maxit)
knitr::opts_chunk$set(echo = TRUE)
mcnorm <- function (n, a, b) {
x = runif(n,a,b)
g = exp(-x)/(1+x^2)
tetah=(b-a)*mean(g) # this is the Monte Carlo approximation to the integral
tetah_se=(b-a)*sd(g)/sqrt(n) #This is the standard error of the approimation
list(tetah=tetah,tetah_se=tetah_se)
}
n = 20000
a=0; b=1
I.4 = mcnorm(n,a,b)
output <- data.frame( M_C_approx = I.4$tetah, S.E. = I.4$tetah_se)
print(output)
u = runif(n/2,0,1)
gu1 = exp(-u)/(1+u^2)
gu2 = exp(-(1-u))/(1+(1-u)^2)
tetah_b = sum(gu1+gu2)/n
tetaha_b_se = sd(gu1+gu2)/sqrt(n)
print(c(tetah_b,tetaha_b_se))
cor(gu1,gu2)
a.2=function(u){
x=-log(1-(1-1/exp(1))*u)
return(x)
}
n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
c = runif(n/2,0,1)
u = a.2(c)
gu1 = exp(-u)/(1+u^2)
gu2 = exp(-(1-u))/(1+(1-u)^2)
tetah_c = sum(gu1+gu2)/n
tetaha_c_se = sd(gu1+gu2)/sqrt(n)
print(c(tetah_c,tetaha_c_se))
library(MASS)
hitmiss <- function (n, mu, sigma,a , b, c) {
s=mvrnorm( n, mu, sigma, tol = 1e-6, empirical = FALSE)
tetah = sum(s[,1]<a & s[,2]<b & s[,3]<c)/n # this is the hit-miss approximation to the integral
tetah_se = sqrt((tetah-tetah^2)/n) #This is the standard error of the approimation
return(list(tetah=tetah,tetah_se=tetah_se))
}
n = 20000
a=1; b=4; c=2
mu=c(0,0,0)
sigma = matrix(c(1,3/5,1/3,3/5,1,11/15,1/3,11/15,1),3,3)
I = hitmiss(n, mu, sigma, a, b, c)
I
theta = I$tetah
stdv = I$tetah_se
z = qnorm(.9725,0,1)
lower.bound = theta-z*stdv
upper.bound = theta+z*stdv
print("       Confidence Interval",quote = FALSE)
paste0("(", lower.bound ,",",upper.bound  ,")")
n = 20000
mu = exp(-.5)*atan(1)
x = runif(n,0,1)
g = (1/(1+x^2))*exp(-x)
h = (1/(1+x^2))*exp(-.5)
c.star = -cov(h,g)/var(h)
theta.hat.c = sum(g+c.star*(h-mu))/n
theta.hat.c = mean(g+c.star*(h-mu))
theta.hat.c
sqrt(I.4$tetah_se^2-cor(g,h)^2*I.4$tetah_se^2)
var.cv=(1/n)*(var(g)-(cov(g,h)^2)/var(h))
se.cv=sqrt(var.cv)
se.cv
n = 20000
u = runif(n,0,1)
x=1-sqrt(1-u)
g = (1/(1+x^2))*exp(-x)
h = (1/(1+x^2))*exp(-.5)
f=2*(1-x)
gf=g/f
hf=h/f
mu=exp(-.5)*atan(1)
c.star = -cov(hf,gf)/var(hf)
theta.hat.c = sum(gf+c.star*(hf-mu))/n
theta.hat.c = mean(gf+c.star*(hf-mu))
theta.hat.c
var.cv=(1/n)*(var(gf)-(cov(gf,hf)^2)/var(hf))
se.cv=sqrt(var.cv)
se.cv
library(mvtnorm)
library(RVAideMemoire)
library(rstatix)
library(mnormt)
library(nFactors)
setwd('C:\\Users\\User\\Desktop\\School\\Math_537\\Test2')
data=read.table('Apple.txt', header=T)
head(data)
######################################################
#1 a)
y=cbind(data$y1,data$y2,data$y3,data$y4)
model=manova(y~as.factor(Rootstock),data=data)
lam=summary.manova(model,test="Wilks")$stats[3]
lam
######################################################
#1 b)
temp=summary.manova(model,test="Wilks")
temp$SS$Residuals
model$residuals
mqqnorm(model$residuals)
#fairly normal
box_m(y, data$Rootstock)
# With a p-value of .711 this implies that each y_i came from similar variances.
######################################################
#1 c)
n=10000
lam2=matrix(0,1,n)
data2=as.matrix(data)
ind=sample(1:48,replace=T)
final=cbind((data2[,1]),(data2[ind,2:5]))
results= final[,2:5]
y=cbind(final[,2],final[,3],final[,4],final[,5])
model=manova(y~as.factor(final[,1]),data=as.data.frame(final))
lam2[1]=summary.manova(model,test="Wilks")$stats[3]
for(i in 2:n)
{
ind=sample(1:48,replace=T)
final=cbind((data2[,1]),(data2[ind,2:5]))
results=results+final[,2:5]
y=cbind(final[,2],final[,3],final[,4],final[,5])
model=manova(y~as.factor(final[,1]),data=as.data.frame(final))
lam2[i]=summary.manova(model,test="Wilks")$stats[3]
}
sum(lam2<lam)/n
results=results/n
results=cbind((data2[,1]),results)
y=cbind(results[,2],results[,3],results[,4],results[,5])
model=manova(y~as.factor(results[,1]),data=as.data.frame(results))
mqqnorm(model$residuals)
######################################################
#2 a)
data2=read.table('drivPoints.txt', sep=",", header=T)
data2F=scale(data2[,6:dim(data2)[2]],scale=F)
pca = prcomp(data2F)
pca
plot(pca,type="l")
source("ggbiplot2.R")
componet=pca$rotation[,1:2]
#All principle components printed
g = ggbiplot(pca, obs.scale = 1, var.scale = 1,
groups = as.factor(data2[,4]), ellipse = TRUE,
circle = TRUE)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal',
legend.position = 'top')
g
#Only the first two principle componenets printed (important ones)
g = ggbiplot(pca, obs.scale = 1, var.scale = 1,
groups = as.factor(data2[,4]), ellipse = TRUE,
circle = TRUE,numComp=2)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal',
legend.position = 'top')
g
head(data2)
######################################################
#2 b)
X=data2F
f1=factanal(data2F,factors=9,rotation="varimax")
f2=factanal(data2F,factors=4,rotation="varimax")
ev <- eigen(cor(X)) # get eigenvalues
ap <- parallel(subject=nrow(X),var=ncol(X),
rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)
.rs.restartR()
library(mvtnorm)
library(RVAideMemoire)
library(rstatix)
library(mnormt)
library(nFactors)
setwd('C:\\Users\\User\\Desktop\\School\\Math_537\\Test2')
data=read.table('Apple.txt', header=T)
head(data)
######################################################
#1 a)
y=cbind(data$y1,data$y2,data$y3,data$y4)
model=manova(y~as.factor(Rootstock),data=data)
lam=summary.manova(model,test="Wilks")$stats[3]
lam
######################################################
#1 b)
temp=summary.manova(model,test="Wilks")
temp$SS$Residuals
model$residuals
mqqnorm(model$residuals)
#fairly normal
box_m(y, data$Rootstock)
# With a p-value of .711 this implies that each y_i came from similar variances.
######################################################
#1 c)
n=10000
lam2=matrix(0,1,n)
data2=as.matrix(data)
ind=sample(1:48,replace=T)
final=cbind((data2[,1]),(data2[ind,2:5]))
results= final[,2:5]
y=cbind(final[,2],final[,3],final[,4],final[,5])
model=manova(y~as.factor(final[,1]),data=as.data.frame(final))
lam2[1]=summary.manova(model,test="Wilks")$stats[3]
for(i in 2:n)
{
ind=sample(1:48,replace=T)
final=cbind((data2[,1]),(data2[ind,2:5]))
results=results+final[,2:5]
y=cbind(final[,2],final[,3],final[,4],final[,5])
model=manova(y~as.factor(final[,1]),data=as.data.frame(final))
lam2[i]=summary.manova(model,test="Wilks")$stats[3]
}
sum(lam2<lam)/n
results=results/n
results=cbind((data2[,1]),results)
y=cbind(results[,2],results[,3],results[,4],results[,5])
model=manova(y~as.factor(results[,1]),data=as.data.frame(results))
mqqnorm(model$residuals)
######################################################
#2 a)
data2=read.table('drivPoints.txt', sep=",", header=T)
data2F=scale(data2[,6:dim(data2)[2]],scale=F)
pca = prcomp(data2F)
pca
plot(pca,type="l")
source("ggbiplot2.R")
componet=pca$rotation[,1:2]
#All principle components printed
g = ggbiplot(pca, obs.scale = 1, var.scale = 1,
groups = as.factor(data2[,4]), ellipse = TRUE,
circle = TRUE)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal',
legend.position = 'top')
g
#Only the first two principle componenets printed (important ones)
g = ggbiplot(pca, obs.scale = 1, var.scale = 1,
groups = as.factor(data2[,4]), ellipse = TRUE,
circle = TRUE,numComp=2)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal',
legend.position = 'top')
g
head(data2)
######################################################
#2 b)
X=data2F
f1=factanal(data2F,factors=9,rotation="varimax")
f2=factanal(data2F,factors=4,rotation="varimax")
ev <- eigen(cor(X)) # get eigenvalues
ap <- parallel(subject=nrow(X),var=ncol(X),
rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)
version
update()
library(installr)
install.packages("installr")
updateR()
library(installr)
updateR()
