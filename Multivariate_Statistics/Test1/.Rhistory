cuts=cut(h$breaks,c(-Inf,-0.000001,0,Inf))
plot(h,col=c("white","red")[cuts])
cuts=cut(h$breaks,c(-Inf,-0.000001,0,100000))
plot(h,col=c("white","red")[cuts])
cuts=cut(h$breaks,c(-Inf,-0.000001,Inf))
plot(h,col=c("white","red")[cuts])
#create histogram
h=hist(bsStat,breaks=100,plot=F)
cuts=cut(h$breaks,c(-Inf,-0.000001,Inf))
plot(h,col=c("white","red")[cuts])
plot(h,main="Bias Toward Higher Men Salaries",col=c("white","red")[cuts])
p.val.bs
#bootstraping
for(i in 1:1000000){
#creating populations to use in bootstraping statistic
femBS[i]=mean(sample(femalesKeep,104,replace=T))
maleBS[i]=mean(sample(males,115,replace=T))
#creating bootstraping statistic
bsStat[i]=maleBS[i]-femBS[i]
}
#Generate P-values for boostraping using >0 as the cut off for difference
p.val.bs = length(bsStat[bsStat>0])/length(bsStat)
p.val.bs
for(i in 1:1000000){
#creating populations to use in bootstraping statistic
femBS[i]=mean(sample(femalesKeep,104,replace=T))
maleBS[i]=mean(sample(males,115,replace=T))
#creating bootstraping statistic
bsStat[i]=femBS[i]-maleBS[i]
#bootstraping
for(i in 1:1000000){
#creating populations to use in bootstraping statistic
femBS[i]=mean(sample(femalesKeep,104,replace=T))
maleBS[i]=mean(sample(males,115,replace=T))
#creating bootstraping statistic
bsStat[i]=femBS[i]-maleBS[i]
}
knitr::opts_chunk$set(echo = TRUE)
trivariatenormal <- read.table("C:/Users/Amanda/Desktop/Math 534/Homework 10/trivariatenormal.dat", quote="\"", comment.char="",header=T)
knitr::opts_chunk$set(echo = TRUE)
trivariatenormal <- read.table("trivariatenormal.dat", quote="\"", comment.char="",header=T)
View(trivariatenormal)
attach(trivariatenormal)
setwd("C:/Users/User/Desktop/School/Math_534/HW/HW5")
mu=c(0,0,0)
sig=matrix(c(1,0,0,0,1,0,0,0,1),3,3)
maxit=50
em=function(X,mu,sig,maxit){
#browser()
n=dim(X)[1]
p=dim(X)[2]
it=0
stop=0
header=paste0("  it","   mu1  ","    mu3  ","   Sig11","    Sig13  ","   ||grad||   ")
print(header,quote = FALSE)
while(it<maxit && stop==0){
it=it+1
ex1=matrix(0,p,1)
exx1=matrix(0,p,p)
for(i in 1:n){
ex=t(as.matrix(X[i,]))
exx=matrix(0,p,p)
obs=which(!is.na(X[i,]))
mis=which(is.na(X[i,]))
if(any(is.na(X[i,]))==TRUE ){
mu_o=matrix(mu[obs])
mu_m=matrix(mu[mis])
Soo = matrix(sig[obs,obs], length(obs), length(obs))
Smo = matrix(sig[mis,obs], length(mis), length(obs))
Som = matrix(sig[obs,mis], length(obs), length(mis))
Smm = matrix(sig[mis,mis], length(mis), length(mis))
yo=t(as.matrix(X[i,obs]))
y.m.star=mu_m+Smo%*%solve(Soo)%*%(yo-mu_o)
ex[mis]=y.m.star
exx[obs,obs] = yo%*%t(yo)
exx[mis,obs] = y.m.star%*%t(yo)
exx[obs,mis] = yo%*%t(y.m.star)
exx[mis,mis] = Smm-Smo%*%solve(Soo)%*%Som+y.m.star%*%t(y.m.star)
}
else{
yo=t(as.matrix(X[i,obs]))
exx[obs,obs]=yo%*%t(yo)
}
ex1=ex+ex1
exx1=exx+exx1
}
# e-step
#
x.bar.star=ex1/n
s.star=exx1/n
#m-step
#
mu.hat=x.bar.star
sig.hat=s.star-x.bar.star%*%t(x.bar.star)
# gradient
#
invsig=solve(sig)
gradM=-n*invsig%*%(mu-x.bar.star)
A = s.star-mu%*%t(x.bar.star)-x.bar.star%*%t(mu)+mu%*%t(mu)
B = invsig%*%(sig-A)%*%invsig
C=(-n/2)*(B+t(B)-diag(diag(B)))
gradS=C[upper.tri(C,diag = TRUE)==TRUE]
grad=matrix(0,p+p*(p+1)/2,1)
grad[1:p] = gradM
grad[(p+1):length(grad)] = gradS
norm=norm(grad,type = "f")
# reassigning mu and sig
#
if(it==1||it==2||it==3||it==33||it==34||it==35){
print(sprintf(' %2.0f %8.5f %8.5f %8.5f %8.5f %8.7f ',(it-1),mu[1],mu[3],sig[1,1],sig[1,3],norm),quote=FALSE)
}
mu=mu.hat
sig=sig.hat
if(norm<1e-6)stop=1
}
list(mu=mu,sig=sig)
}
em(trivariatenormal,mu,sig,maxit)
knitr::opts_chunk$set(echo = TRUE)
mcnorm <- function (n, a, b) {
x = runif(n,a,b)
g = exp(-x)/(1+x^2)
tetah=(b-a)*mean(g) # this is the Monte Carlo approximation to the integral
tetah_se=(b-a)*sd(g)/sqrt(n) #This is the standard error of the approimation
list(tetah=tetah,tetah_se=tetah_se)
}
n = 20000
a=0; b=1
I.4 = mcnorm(n,a,b)
output <- data.frame( M_C_approx = I.4$tetah, S.E. = I.4$tetah_se)
print(output)
u = runif(n/2,0,1)
gu1 = exp(-u)/(1+u^2)
gu2 = exp(-(1-u))/(1+(1-u)^2)
tetah_b = sum(gu1+gu2)/n
tetaha_b_se = sd(gu1+gu2)/sqrt(n)
print(c(tetah_b,tetaha_b_se))
cor(gu1,gu2)
a.2=function(u){
x=-log(1-(1-1/exp(1))*u)
return(x)
}
n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
c = runif(n/2,0,1)
u = a.2(c)
gu1 = exp(-u)/(1+u^2)
gu2 = exp(-(1-u))/(1+(1-u)^2)
tetah_c = sum(gu1+gu2)/n
tetaha_c_se = sd(gu1+gu2)/sqrt(n)
print(c(tetah_c,tetaha_c_se))
library(MASS)
hitmiss <- function (n, mu, sigma,a , b, c) {
s=mvrnorm( n, mu, sigma, tol = 1e-6, empirical = FALSE)
tetah = sum(s[,1]<a & s[,2]<b & s[,3]<c)/n # this is the hit-miss approximation to the integral
tetah_se = sqrt((tetah-tetah^2)/n) #This is the standard error of the approimation
return(list(tetah=tetah,tetah_se=tetah_se))
}
n = 20000
a=1; b=4; c=2
mu=c(0,0,0)
sigma = matrix(c(1,3/5,1/3,3/5,1,11/15,1/3,11/15,1),3,3)
I = hitmiss(n, mu, sigma, a, b, c)
I
theta = I$tetah
stdv = I$tetah_se
z = qnorm(.9725,0,1)
lower.bound = theta-z*stdv
upper.bound = theta+z*stdv
print("       Confidence Interval",quote = FALSE)
paste0("(", lower.bound ,",",upper.bound  ,")")
n = 20000
mu = exp(-.5)*atan(1)
x = runif(n,0,1)
g = (1/(1+x^2))*exp(-x)
h = (1/(1+x^2))*exp(-.5)
c.star = -cov(h,g)/var(h)
theta.hat.c = sum(g+c.star*(h-mu))/n
theta.hat.c = mean(g+c.star*(h-mu))
theta.hat.c
sqrt(I.4$tetah_se^2-cor(g,h)^2*I.4$tetah_se^2)
var.cv=(1/n)*(var(g)-(cov(g,h)^2)/var(h))
se.cv=sqrt(var.cv)
se.cv
n = 20000
u = runif(n,0,1)
x=1-sqrt(1-u)
g = (1/(1+x^2))*exp(-x)
h = (1/(1+x^2))*exp(-.5)
f=2*(1-x)
gf=g/f
hf=h/f
mu=exp(-.5)*atan(1)
c.star = -cov(hf,gf)/var(hf)
theta.hat.c = sum(gf+c.star*(hf-mu))/n
theta.hat.c = mean(gf+c.star*(hf-mu))
theta.hat.c
var.cv=(1/n)*(var(gf)-(cov(gf,hf)^2)/var(hf))
se.cv=sqrt(var.cv)
se.cv
library(ellipse)
library(Rfast)
setwd("C:\\Users\\User\\Desktop\\School\\Math_537\\Test1")
data=read.csv("genderwage.csv")
############################################
#1 a)
x=data$female
y=data$male
n=length(x)
variance=matrix(var(data),ncol=2)/n
muX=mean(x)
muY=mean(y)
mu=matrix(c(muX,muY),2,1)
muT=mean(cbind(x,y))
findMu=function(x,mu,variance)
{
xy=c(x,x)
result=t(mu-xy)%*%solve(variance)%*%(mu-xy)
return(result)
}
result=optim(par=20,fn=findMu,mu=mu,variance=variance)
mu0=matrix(c(result$par,result$par),2,1)
t2=t(mu-mu0)%*%solve(variance)%*%(mu-mu0)
pval=1-pf((n-2)/((n-1)*2)*t2,2,n-2)
############################################
#1 b)
eig=eigen(variance)
lam1=eig$values[1]
lam2=eig$values[2]
v1=eig$vectors[,1]
v2=eig$vectors[,2]
dist =(2*(n-1)/(n-2))*qf(.95,2,n-2)
a1=v1*sqrt(lam1)*sqrt(dist)
a2=v2*sqrt(lam2)*sqrt(dist)
plot(x,y)
points(muX,muY,pch=19,cex=1,col=2)
plot(x,y,xlim=(c(15,26)),ylim=(c(17,29)))
points(muX,muY,pch=19,cex=1,col=2)
lines(ellipse(variance,centre=c(muX,muY)),col=3)
lines(c(muX,muX+a1[1]),c(muY,muY+a1[2]),lwd=.5,col=2)
lines(c(muX,muX+a2[1]),c(muY,muY+a2[2]),lwd=.5,col=2)
lines(c(18,18),c(26,26),lwd=.5,col=2)
c(muX,muX+a2[1])
c(muY,muY+a2[2])
abline(c(18,18),c(26,26),lwd=.5,col=2)
abline(c(18,26),c(28,26),lwd=.5,col=2)
lines(c(18,26),c(28,26),lwd=.5,col=2)
lines(c(18,26),c(18,26),lwd=.5,col=2)
lines(c(0,28),c(0,28),lwd=.5,col=2)
library(ellipse)
library(Rfast)
setwd("C:\\Users\\User\\Desktop\\School\\Math_537\\Test1")
data=read.csv("genderwage.csv")
############################################
#1 a)
x=data$female
y=data$male
n=length(x)
variance=matrix(var(data),ncol=2)/n
muX=mean(x)
muY=mean(y)
mu=matrix(c(muX,muY),2,1)
muT=mean(cbind(x,y))
findMu=function(x,mu,variance)
{
xy=c(x,x)
result=t(mu-xy)%*%solve(variance)%*%(mu-xy)
return(result)
}
result=optim(par=20,fn=findMu,mu=mu,variance=variance)
mu0=matrix(c(result$par,result$par),2,1)
t2=t(mu-mu0)%*%solve(variance)%*%(mu-mu0)
pval=1-pf((n-2)/((n-1)*2)*t2,2,n-2)
############################################
#1 b)
eig=eigen(variance)
lam1=eig$values[1]
lam2=eig$values[2]
v1=eig$vectors[,1]
v2=eig$vectors[,2]
dist =(2*(n-1)/(n-2))*qf(.95,2,n-2)
a1=v1*sqrt(lam1)*sqrt(dist)
a2=v2*sqrt(lam2)*sqrt(dist)
plot(x,y)
points(muX,muY,pch=19,cex=1,col=2)
plot(x,y,xlim=(c(15,26)),ylim=(c(17,29)))
points(muX,muY,pch=19,cex=1,col=2)
lines(ellipse(variance,centre=c(muX,muY)),col=3)
lines(c(muX,muX+a1[1]),c(muY,muY+a1[2]),lwd=.5,col=2)
lines(c(muX,muX+a2[1]),c(muY,muY+a2[2]),lwd=.5,col=2)
lines(c(0,28),c(0,28),lwd=.5,col=2)
points(mu0[1],mu0[2],pch=19,cex=1,col=2)
points(muX,muY,pch=19,cex=1,col=3)
lowerX=muX-qt(.975,n-1)*sd(x)/sqrt(n)
upperX=muX+qt(.975,n-1)*sd(x)/sqrt(n)
print(lowerX)
print(muX)
print(upperX)
lowerY=muY-qt(.975,n-1)*sd(y)/sqrt(n)
upperY=muY+qt(.975,n-1)*sd(y)/sqrt(n)
print(lowerY)
print(muY)
print(upperY)
library(ellipse)
library(Rfast)
setwd("C:\\Users\\User\\Desktop\\School\\Math_537\\Test1")
data=read.csv("genderwage.csv")
############################################
#1 a)
x=data$female
y=data$male
n=length(x)
variance=matrix(var(data),ncol=2)/n
muX=mean(x)
muY=mean(y)
mu=matrix(c(muX,muY),2,1)
muT=mean(cbind(x,y))
findMu=function(x,mu,variance)
{
xy=c(x,x)
result=t(mu-xy)%*%solve(variance)%*%(mu-xy)
return(result)
}
result=optim(par=20,fn=findMu,mu=mu,variance=variance)
mu0=matrix(c(result$par,result$par),2,1)
t2=t(mu-mu0)%*%solve(variance)%*%(mu-mu0)
pval=1-pf((n-2)/((n-1)*2)*t2,2,n-2)
pval
############################################
#1 b)
eig=eigen(variance)
lam1=eig$values[1]
lam2=eig$values[2]
v1=eig$vectors[,1]
v2=eig$vectors[,2]
dist =(2*(n-1)/(n-2))*qf(.95,2,n-2)
a1=v1*sqrt(lam1)*sqrt(dist)
a2=v2*sqrt(lam2)*sqrt(dist)
plot(x,y,xlim=(c(15,26)),ylim=(c(17,29)))
points(muX,muY,pch=19,cex=1,col=3)
lines(ellipse(variance,centre=c(muX,muY)),col=3)
lines(c(muX,muX+a1[1]),c(muY,muY+a1[2]),lwd=.5,col=2)
lines(c(muX,muX+a2[1]),c(muY,muY+a2[2]),lwd=.5,col=2)
lines(c(0,28),c(0,28),lwd=.5,col=2)
points(mu0[1],mu0[2],pch=19,cex=1,col=2)
lowerX=muX-qt(.975,n-1)*sd(x)/sqrt(n)
upperX=muX+qt(.975,n-1)*sd(x)/sqrt(n)
print(lowerX)
print(muX)
print(upperX)
lowerY=muY-qt(.975,n-1)*sd(y)/sqrt(n)
upperY=muY+qt(.975,n-1)*sd(y)/sqrt(n)
print(lowerY)
print(muY)
print(upperY)
xa = mean(x) - qt(.9875,length(x)-1)*sd(x)/sqrt(length(x))
xb = mean(x) + qt(.9875,length(x)-1)*sd(x)/sqrt(length(x))
ya = mean(y) - qt(.9875,length(y)-1)*sd(y)/sqrt(length(y))
yb = mean(y) + qt(.9875,length(y)-1)*sd(y)/sqrt(length(y))
lines(c(xa,xb),c(ya,ya),lty=2,col=4)
lines(c(xa,xb),c(yb,yb),lty=2,col=4)
lines(c(xa,xa),c(ya,yb),lty=2,col=4)
lines(c(xb,xb),c(ya,yb),lty=2,col=4)
mu0
likeRatio
library(ellipse)
library(Rfast)
setwd("C:\\Users\\User\\Desktop\\School\\Math_537\\Test1")
data=read.csv("genderwage.csv")
############################################
#1 a)
x=data$female
y=data$male
n=length(x)
variance=matrix(var(data),ncol=2)/n
muX=mean(x)
muY=mean(y)
mu=matrix(c(muX,muY),2,1)
muT=mean(cbind(x,y))
findMu=function(x,mu,variance)
{
xy=c(x,x)
result=t(mu-xy)%*%solve(variance)%*%(mu-xy)
return(result)
}
result=optim(par=20,fn=findMu,mu=mu,variance=variance)
mu0=matrix(c(result$par,result$par),2,1)
t2=t(mu-mu0)%*%solve(variance)%*%(mu-mu0)
pval=2*(1-pf((n-2)/((n-1)*2)*t2,2,n-2))
pval
############################################
#1 b)
eig=eigen(variance)
lam1=eig$values[1]
lam2=eig$values[2]
v1=eig$vectors[,1]
v2=eig$vectors[,2]
dist =(2*(n-1)/(n-2))*qf(.95,2,n-2)
a1=v1*sqrt(lam1)*sqrt(dist)
a2=v2*sqrt(lam2)*sqrt(dist)
plot(x,y,xlim=(c(15,26)),ylim=(c(17,29)))
points(muX,muY,pch=19,cex=1,col=3)
lines(ellipse(variance,centre=c(muX,muY)),col=3)
lines(c(muX,muX+a1[1]),c(muY,muY+a1[2]),lwd=.5,col=2)
lines(c(muX,muX+a2[1]),c(muY,muY+a2[2]),lwd=.5,col=2)
lines(c(0,28),c(0,28),lwd=.5,col=2)
points(mu0[1],mu0[2],pch=19,cex=1,col=2)
############################################
#1 c)
lowerX=muX-qt(.975,n-1)*sd(x)/sqrt(n)
upperX=muX+qt(.975,n-1)*sd(x)/sqrt(n)
print(lowerX)
print(muX)
print(upperX)
lowerY=muY-qt(.975,n-1)*sd(y)/sqrt(n)
upperY=muY+qt(.975,n-1)*sd(y)/sqrt(n)
print(lowerY)
print(muY)
print(upperY)
############################################
#1 d)
xa = mean(x) - qt(.9875,length(x)-1)*sd(x)/sqrt(length(x))
xb = mean(x) + qt(.9875,length(x)-1)*sd(x)/sqrt(length(x))
ya = mean(y) - qt(.9875,length(y)-1)*sd(y)/sqrt(length(y))
yb = mean(y) + qt(.9875,length(y)-1)*sd(y)/sqrt(length(y))
plot(x,y,xlim=(c(15,26)),ylim=(c(17,29)))
points(muX,muY,pch=19,cex=1,col=3)
lines(ellipse(variance,centre=c(muX,muY)),col=3)
lines(c(muX,muX+a1[1]),c(muY,muY+a1[2]),lwd=.5,col=2)
lines(c(muX,muX+a2[1]),c(muY,muY+a2[2]),lwd=.5,col=2)
lines(c(0,28),c(0,28),lwd=.5,col=2)
points(mu0[1],mu0[2],pch=19,cex=1,col=2)
lines(c(xa,xb),c(ya,ya),lty=2,col=4)
lines(c(xa,xb),c(yb,yb),lty=2,col=4)
lines(c(xa,xa),c(ya,yb),lty=2,col=4)
lines(c(xb,xb),c(ya,yb),lty=2,col=4)
############################################
#1 e)
muM=matrix(c(22.5,24.5),2,1)
muR=matrix(c(21.5,26),2,1)
sigM=matrix(c(12,8,8,12),2,2)
sigR=matrix(c(9,8,8,16),2,2)
likeRatio=prod(dmvnorm(as.matrix(data),muM,sigM))/prod(dmvnorm(as.matrix(data),muR,sigR))
#Rachel is the winner, sorry M
############################################
#1 f)
eig=eigen(cov(as.matrix(data)))
vec=eig$vectors
l=eig$values
eMu0=vec[,1]%*%mu0
eX=as.matrix(data)%*%vec[,1]
t=(mean(eX)-eMu0)/(sd(eX)/sqrt(n))
2*(1-pt(t,n-1))
likeRatio
